---
title: "Spore shape vs. size"
output: html_notebook
---

This is an R Notebook containing code and results of comparing the performance  of shape and size traits for discrimination of species in *Subulicystidium*. 
   
**New in this version**:  
* this is largely a duplicate of the version 20210129 but now based on the (for safety) re-run PCA from 17.02.2021  
* removed the non-relevant here description of how to create a single NEF file. 

**To do in the next version**:  
* implement report() in the end of the script
* make illustrations and tables writing to the files with desired dimensions, into kind of 'out' folder  
* Work on aestetics of phylogenetic tree - it goes as a Fig to the ms.  
* Keep actual link to species_names. 
* move PCA analysis of NEFD to R  
* I may also adjust longisporum name in the next analysis version when the data from Christina will be coming. Then my longisporum will become longisporum_7

**Most important changes in the past**: 
* analyses on image-level data, N of observations = 401. Each observation is a data from a single image, with information on min 1 spore and max 4 spores  
* custom function for discriminant analysis that allows to shorten the script  


## Setting the work
### Only first session
At the very start, assign in R studio as a working directory the directory which is parent for the code, data and results directories. Then *set_here* function of the "here" package will pick this assignment by creating the file .here. Then all subsequent R sessions on this project will start with the right directory. 
To see more examples of  "here" visit http://jenrichmond.rbind.io/post/where-is-here/


### Every session
Loading package "here" should notify on the correct working directory.

```{r}
library(here)
library(conflicted)
conflict_prefer("here", "here")
conflicted::conflict_prefer("rename", "dplyr")
```



## Load and proceed spore shape data

### Summarize symmetric variation
Load and process the table with PCA scores for specimens (symmetric variation)
```{r}
scores_symm_raw <- read.csv(here("2_3_data_shape", "pca_202102", "1_symm", "30specimens_clean_symm.pcs"),  sep="\t")

# add column to be filled in later with relevant IDs
scores_symm_raw <- cbind(Specimen_ID = NA, scores_symm_raw)
scores_symm_raw <- cbind(Image_ID = NA, scores_symm_raw)


# fill in column Specimen_ID based on content of the column DATA_NAME
library(stringr)
strings <- c("^ARAN", "^CWU", "^KHL", "^LR", "^LY", "^Ordynets")
scores_symm_raw$Specimen_ID <- ifelse(str_detect(scores_symm_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*)_.*$", "\\1", scores_symm_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_symm_raw$DATA_NAME))

# fill in column Image_ID based on content of the column DATA_NAME
scores_symm_raw$Image_ID <- ifelse(str_detect(scores_symm_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_symm_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_symm_raw$DATA_NAME))
```



Plot PCA scores as scatterplots (symmetric variation)
```{r}
library(ggplot2)
pca_symm_plot<-ggplot(scores_symm_raw, aes(x=Specimen_ID, y=PC1, color=Specimen_ID)) +
geom_point()+
theme(axis.text.x = element_text(angle = 90))
plot(pca_symm_plot)
```

Summarize symmetric variation at the specimen level
`.groups = 'drop'` argument in ```summarise()``` will help to remove a "friendly warning"  
``` `summarise()` ungrouping output (override with `.groups` argument)```  
The explanation is available at https://stackoverflow.com/questions/62140483/how-to-interpret-dplyr-message-summarise-regrouping-output-by-x-override

```{r}
library(dplyr)
scores_symm_summ <- scores_symm_raw %>% 
  group_by(Image_ID) %>% 
  summarise(across(Specimen_ID, dplyr::first),
            across(PC1, mean),
            .groups = 'drop')
scores_symm_summ <- dplyr::rename(scores_symm_summ, PC1_symm_mean = PC1)
```



### Summarize asymmetric variation
Load and process the table with PCA scores for specimens (asymmetric variation)

```{r}
scores_asym_raw <- read.csv(here("2_3_data_shape", "pca_202102", "2_asym", "30specimens_clean_asym.pcs"),  sep="\t")

# add column to be filled in later with relevant IDs
scores_asym_raw <- cbind(Specimen_ID = NA, scores_asym_raw)
scores_asym_raw <- cbind(Image_ID = NA, scores_asym_raw)

# fill in column Specimen_ID based on content of the column DATA_NAME.
# "strings" object was created above and is valid here as is.
# Package "stringr" is necessary and was loaded earlier.
scores_asym_raw$Specimen_ID <- ifelse(str_detect(scores_asym_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*)_.*$", "\\1", scores_asym_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_asym_raw$DATA_NAME))

# fill in column Image_ID based on content of the column DATA_NAME.
scores_asym_raw$Image_ID <- ifelse(str_detect(scores_asym_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_asym_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_asym_raw$DATA_NAME))
```

Plot PCA scores as scatterplots (asymmetric variation): PC1 vs PC2
```{r}
library(ggplot2)
pca_asym_plot<-ggplot(scores_asym_raw, aes(x=PC1, y=PC2, color=Specimen_ID)) +
geom_point()
plot(pca_asym_plot)
```

Plotting PCA scores as scatterplots (asymmetric variation): PC1 vs PC3
```{r}
library(ggplot2)
pca_asym_plot<-ggplot(scores_asym_raw, aes(x=PC1, y=PC3, color=Specimen_ID)) +
geom_point()
plot(pca_asym_plot)
```

Summarize asymmetric variation at image level
```{r}
# Averaging per specimen
library(dplyr)
scores_asym_summ <- scores_asym_raw %>% 
  group_by(Image_ID) %>% 
  summarise(PC1_asym_mean=mean(PC1),
            PC2_asym_mean=mean(PC2),
            PC3_asym_mean=mean(PC3), 
            .groups = 'drop')
```


### Summarize global variation
Load and process the table with PCA scores for specimens (global variation)
```{r}
scores_glob_raw <- read.csv(here("2_3_data_shape", "pca_202102", "3_glob", "30specimens_clean_glob.pcs"),  sep="\t")

# add column to be filled in later with relevant IDs
scores_glob_raw <- cbind(Specimen_ID = NA, scores_glob_raw)
scores_glob_raw <- cbind(Image_ID = NA, scores_glob_raw)

# fill in column Specimen_ID based on content of the column DATA_NAME
# "strings" object was created above and is valid here as is.
# Package "stringr" is necessary and was loaded eralier.
scores_glob_raw$Specimen_ID <- ifelse(str_detect(scores_glob_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*)_.*$", "\\1", scores_glob_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_glob_raw$DATA_NAME))

scores_glob_raw$Image_ID <- ifelse(str_detect(scores_glob_raw$DATA_NAME, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_glob_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_glob_raw$DATA_NAME))
```

Plotting PCA scores as scatterplots (global variation): PC1 vs PC2
```{r}
library(ggplot2)
pca_glob_plot<-ggplot(scores_glob_raw, aes(x=PC1, y=PC2, color=Specimen_ID)) +
geom_point()
plot(pca_glob_plot)
```

Summarize global variation at specimen level
```{r}
# Averaging per specimen
library(dplyr)
scores_glob_summ <- scores_glob_raw %>% 
  group_by(Image_ID) %>% 
  summarise(PC1_glob_mean=mean(PC1),
            PC2_glob_mean=mean(PC2), 
            .groups = 'drop')
```

 

## Load and proceed spore size data
Spore size data from separate specimens get pooled.  
I will suppress the warning message "Missing column names filled in: 'X1' [1]" that is generated by "read.csv" function which is forced to give a name to the unnamed column. 
```{r message = FALSE}
library(here)
library(readr)
import.size <- dir(here("2_2_data_size", "v20201215"), pattern = "*.csv", full.names = T)
data_size_raw <- suppressWarnings(plyr::ldply(import.size, read_csv))
```


Then the spreadsheeet is transformed to put length and width  for each spore to separate columns of one row.    Warning message from dplyr when binding length and width columns "New names: * X1 -> X1...1..." that appears after the code chunk can be ignored.  
Then, length to width ratio is added as an additional column.   
Finally, column "Image_ID" is created.  

```{r}
library(dplyr)
data_size_raw_odd <- data_size_raw %>% dplyr::slice(which(row_number() %% 2 == 1))
colnames(data_size_raw_odd)[which(names(data_size_raw_odd) == "Label")] <- "Photo_ID"

data_size_raw_even <- data_size_raw %>% dplyr::slice(which(row_number() %% 2 == 0)) 
colnames(data_size_raw_even)[which(names(data_size_raw_even) == "Length")] <- "Width"

data_size_tiny <- bind_cols(data_size_raw_odd, data_size_raw_even)
data_size_tiny_simple <-data_size_tiny[, c("Photo_ID", "Length", "Width")]

data_size_tiny_simple <- transform(data_size_tiny_simple, Length_to_width_ratio = Length / Width)
data_size_tiny_simple$Length_to_width_ratio <- round(data_size_tiny_simple$Length_to_width_ratio, 2)

data_size_tiny_simple <- cbind(Image_ID = NA, data_size_tiny_simple)

## code that using regex is based on the solution for gsub 
## ## https://stackoverflow.com/questions/39366759/regex-to-extract-values-between-2-underscores-including-a-value-that-is-an-unde
## https://stackoverflow.com/questions/7449564/regex-return-all-before-the-second-occurrence 

library(stringr)
strings <- c("^ARAN", "^CWU", "^KHL", "^LR", "^LY", "^Ordynets")
data_size_tiny_simple$Image_ID <- ifelse(str_detect(data_size_tiny_simple$Photo_ID, paste(strings, collapse = "|")), gsub("^([^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", scores_symm_raw$DATA_NAME), gsub("^([^_]*_[^_]*_[^_]*_[^_]*_[^_]*)_.*$", "\\1", data_size_tiny_simple$Photo_ID))

#remove ".bmp" string pattern from some image IDs 
data_size_tiny_simple$Image_ID <- gsub(pattern = ".bmp*", replacement = "", x = data_size_tiny_simple$Image_ID)
```

Summarize size data at the image level 
```{r}
size_summ <- data_size_tiny_simple %>% 
  group_by(Image_ID) %>% 
  summarise(Length_mean=mean(Length),
            Width_mean=mean(Width),
            Length_to_width_ratio_mean=mean(Length_to_width_ratio),
            N_spores = n(),
              .groups = 'drop')
```


In this way I exported specimen IDs (n = 30) and assigned them to species for further analysis.
If the new specimens will be added to the dataset after summer 2020, the table with species name labels will be updated. 
```{r}
# not run
# readr::write_csv(size_summ$Specimen_ID, file = here("3_results", "species_names_raw.csv", quote = F, sep = ",")
```


The chunk below allows to add a variable with an alternative size definition, following Claude 2008 book (p. 98-99).  
It is a possible alternative to single length and width measurements.  
This measure of size would correlate less with shape variables, which is a desired behavior.  
However, if used in in discriminant analysis, it did not allow to gain in species prediction (tried in Feb 2020, not shown in the code below but can be easily added). 
```{r}
# size_summ$Size_scaled <- NA
# size_summ$Size_scaled <- sqrt(size_summ$Length_mean * size_summ$Width_mean)
# size_summ <- size_summ %>% relocate(Size_scaled, .before = 'Length_mean') # cosmetic changes 
```



## Unite shape and size data
### Check that Images IDs are in the same order in all objects. They will serve as grouping variable

Check for image level data (n=401 in Dez 2020). Here, no need to sort the data in each group because they are all after applying ```summarise()``` function
```{r}
sapply(list(scores_symm_summ$Image_ID, scores_asym_summ$Image_ID, scores_glob_summ$Image_ID),
            FUN = all.equal.list, size_summ$Image_ID)
```


### Create a united table with all traits

Join separate dataframes
```{r}
library(dplyr)
traits_merged <- scores_symm_summ %>% right_join(scores_asym_summ) %>% right_join(scores_glob_summ) %>% right_join(size_summ, by = "Image_ID")
```

Add a column with species names based on data from another table
```{r}
traits_merged <- cbind(Species_ID = NA, traits_merged)
traits_merged$Species_ID <- traits_merged$Specimen_ID
sp_names <- read.csv(here("3_results", "species_names.csv"),  sep=",", stringsAsFactors=FALSE)

library(data.table)
traits_merged_dt <- data.table(traits_merged)
traits_merged_dt[, Species_ID := as.character(factor(Species_ID, labels = sp_names$Species_ID))]
traits_merged <- data.frame(traits_merged_dt)
```

Export the table with traits on image level for supplementary
```{r}
# not run
readr::write_csv(traits_merged, file = here("3_results", "traits_per_image.csv"))
```



##  Data exploration

### Scatterplots for separate traits
```{r}
library(ggplot2)
# Visualize asymmetric variation at specimen level: PC1 vs PC2
gg_asym_PC1vPC2 <- ggplot(traits_merged, aes(x=PC1_asym_mean, y=PC2_asym_mean, color=Species_ID)) +
  geom_point(size = 1, alpha = 0.7) +
  labs(tag = "A", x = "PC1 asymmetric", y = "PC2 asymmetric", color ="Species")

# Visualize asymmetric variation at specimen level: PC1 vs PC3
gg_asym_PC1vPC3 <- ggplot(traits_merged, aes(x=PC1_asym_mean, y=PC3_asym_mean, color=Species_ID)) +
  geom_point(size = 1, alpha = 0.7) + 
  labs(tag = "B", x = "PC1 asymmetric", y = "PC3 asymmetric")

# Visualize symmetric shape variation at specimen level: PC1
# Note that the values on axis y (actually x before flipping) are in reverse order for comparability with the values for Q 
gg_symm_PC1 <- ggplot(traits_merged, aes(x=PC1_symm_mean, color=Species_ID)) +
geom_boxplot() +
coord_flip() +
scale_x_reverse() + 
labs(tag = "C", x = "PC1 symmetric")

# Visualize global variation at specimen level: PC1 vs PC2
gg_glob_PC1vPC2 <-ggplot(traits_merged, aes(x=PC1_glob_mean, y=PC2_glob_mean, color=Species_ID)) + 
  geom_point(size = 1, alpha = 0.7) +
  labs(tag = "D", x = "PC1 global", y = "PC2 global")

# Visualize size variation at specimen level: Length vs width
gg_size_LvW <-ggplot(traits_merged, aes(x=Length_mean, y=Width_mean, color=Species_ID)) +
  geom_point(size = 1, alpha = 0.7) +
  labs(tag = "E", x = "Length", y = "Width")

# Visualize Q variation at specimen level
gg_size_Q <-ggplot(traits_merged, aes(x=Length_to_width_ratio_mean, color=Species_ID)) +
  geom_boxplot() + 
  coord_flip() + 
  labs(tag = "F", x = "Length to width ratio")
```

### Scatterplots for traits in a single combined plot
```{r}
#conflicted::conflict_prefer("rename", "dplyr")
library(ggpubr)
gg_pcas <- ggarrange(gg_asym_PC1vPC2, gg_asym_PC1vPC3, gg_symm_PC1, gg_glob_PC1vPC2, gg_size_LvW, gg_size_Q, common.legend = TRUE, legend = "bottom", align = "hv") + 
  theme(plot.margin = margin(0.3, 0.6, 0.3, 0.3, 'cm')) 
```

Print the plots to a file(s)
```{r}
# tiff
tiff(file = here::here("3_results", "fig_pca.tiff"), height= 13, width=19, units = 'cm', res = 600, 
     compression = "lzw", family = "sans")
print(gg_pcas)
dev.off()

# # pdf
# pdf(file = here::here("3_results", "fig_pca.pdf"), height=5.0, width=7.5)
# print(gg_pcas)
# dev.off()
# 
# # png
# png(file = here::here("3_results", "fig_pca.png"), height= 13, width=19, units = 'cm', res = 500)
# print(gg_pcas)
# dev.off()
```




### Trait data: normality test for each level of the grouping variable
```{r}
shL <- apply(traits_merged[,4:12], 2,  function(x) {RVAideMemoire::byf.shapiro(x ~ Species_ID, data = traits_merged)$tab}) # creates list
shD <- data.table::rbindlist(shL, idcol = T) # converts series of lists to dataframe
# lines just below require dplyr
shD$Species_ID <- rep(levels(factor(traits_merged$Species_ID)), 9) # re-create columnsof species IDs
shD %>% relocate(Species_ID, .after = 1) %>% rename(Trait = .id, Shapiro_W = W, Shapiro_p = 'p-value') -> shD # cosmetic changes 
shD$Shapiro_p <- as.numeric(format(shD$Shapiro_p, scientific=FALSE)) # show p values as decimals
shD
```

In how many % of cases (traits by species) the normality was not met?
```{r}
shapiroNN <- shD$Shapiro_p <= 0.05
nrow(shD[shapiroNN,]) / nrow(shD)
```
There is no universal multivariate normality for levels (defined by species) within traits.



### Trait data: test of variance equality in trait variables between species
```{r}
heplots::leveneTests(traits_merged[,4:12], factor(traits_merged$Species_ID))
```
For each of the traits, covariance between the groups defined by species are not equal. 


### Trait data: overall distributions
```{r}
par(mfrow = c(3,3))
hist(traits_merged$PC1_symm_mean, main = NULL, xlab = "PC1 symmetric")
hist(traits_merged$PC1_asym_mean, main = NULL, xlab = "PC1 asymmetric", ylab = NULL) 
hist(traits_merged$PC2_asym_mean, main = NULL, xlab = "PC2 asymmetric", ylab = NULL)

hist(traits_merged$PC3_asym_mean, main = NULL, xlab = "PC3 asymmetric") 
hist(traits_merged$PC1_glob_mean, main = NULL, xlab = "PC1 global", ylab = NULL) 
hist(traits_merged$PC2_glob_mean, main = NULL, xlab = "PC2 global", ylab = NULL)

hist(traits_merged$Length_mean, main = NULL, xlab = "Length")
hist(traits_merged$Width_mean, main = NULL, xlab = "Width", ylab = NULL) 
hist(traits_merged$Length_to_width_ratio_mean, main = NULL, xlab = "Length to width ratio", ylab = NULL)
# if work from the console, reset graphic settings back with dev.off() 
```



### Multicollinearity check: overall correlations between variables

#### Way 1
Multicollinearity check: corrplot
Get correlation values (Spearman coefficient)
```{r}
traits_merged_forCorr <- dplyr::select(traits_merged,-c("Species_ID", "Image_ID", "Specimen_ID", "N_spores"))
#names(traits_merged_forCorr) this is to get the actual names and to costumize them manually as I do below
names(traits_merged_forCorr) <- c("PC1 symmetric", "PC1 asymmetric", "PC2 asymmetric", 
                                  "PC3 asymmetric", "PC1 global", "PC2 global",
                                  "Length", "Width", "Length to width ratio")
M <- cor(traits_merged_forCorr, method="spearman")
```


Computing the p-value of correlations
To compute the matrix of p-value, a custom R function is used
Source: 
http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram 
```{r}
# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
```


Get p (significance) values for Spearman correlation coefficient
These could not be estimated for all cross-comparisons, apparently due to small data size.
```{r}
p.mat <- cor.mtest(M, method="spearman", exact=FALSE)
```

, fig.align = "center", fig.height = 5, fig.width = 5
Plot correlation values with highlighting only significant (at p=0.05) correlation values
```{r}
library(corrplot)
col <- colorRampPalette(c("#4477AA", "#77AADD", "#FFFFFF", "#EE9988", "#BB4444"))


tiff(file = here::here("3_results", "fig_corr.tiff"), height = 16.5, width = 16.5, units = 'cm', res = 600,
     compression = "lzw", family = "sans")
corrplot(M, method="color", col=col(200),  
         type="upper", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.05, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE)
dev.off()


# # pdf
# pdf(file = here::here("3_results", "fig_corr.pdf"), height=6.5, width=6.5)
# corrplot(M, method="color", col=col(200),  
#          type="upper", 
#          addCoef.col = "black", # Add coefficient of correlation
#          tl.col="black", tl.srt=45, #Text label color and rotation
#          # Combine with significance
#          p.mat = p.mat, sig.level = 0.05, insig = "blank", 
#          # hide correlation coefficient on the principal diagonal
#          diag=FALSE)
# dev.off()
# 
# 
# # png
# png(file = here::here("3_results", "fig_corr.png"), height = 16.5, width = 16.5, units = 'cm', res = 500)
# corrplot(M, method="color", col=col(200),  
#          type="upper", 
#          addCoef.col = "black", # Add coefficient of correlation
#          tl.col="black", tl.srt=45, #Text label color and rotation
#          # Combine with significance
#          p.mat = p.mat, sig.level = 0.05, insig = "blank", 
#          # hide correlation coefficient on the principal diagonal
#          diag=FALSE)
# dev.off()
```



#### Way 2
Multicollinearity check: original data: psych
```{r}
psych::pairs.panels(traits_merged[,4:12], gap = 0, bg = c(1:10)[factor(traits_merged$Species_ID)], pch = 21)
```

Multicollinearity check:log-transformed data: psych:  does not change much and kept just for documentation
```{r}
# psych::pairs.panels(log2(traits_merged[,4:12]), gap = 0, pch = 21, bg = c(1:10)[factor(traits_merged$Species_ID)])
```


#### Way 3
Multicollinearity check: original data: ggplot version
```{r message=FALSE}
# GGally::ggpairs(traits_merged[,4:12])
```





## Discriminant analysis

The non-normal distribution and unequal variance are present. This prevents from using linear discriminant analysis or quadratic discriminant analysis. I will use flexible discriminant analysis.

My code is inspired by:
https://rstudio-pubs-static.s3.amazonaws.com/35817_2552e05f1d4e4db8ba87b334101a43da.html 


Universal function for my discriminant analysis of fungal spores

```{r}
myFDA <- function(y, x, mydata, part, rep){
  # seed for reproducibility
  set.seed(12345)
 
  succ <- dim(rep)
  for (k in 1:rep) {
    
  # define train and test data
  training_samples <- caret::createDataPartition(mydata[, y], p = part, list = FALSE)  
  
  train_data <- mydata[training_samples, ]
  test_data <- mydata[-training_samples, ]
  
  # flexible discriminant analysis
  m <- mda::fda(paste(y, '~',  x), data = train_data)
  # table with predictions for test data
  tablin <- table(factor(test_data[, y]), predict(m, test_data))
  
  # count corrrect predictions = values that are not in the diagonal of "tablin"
  succ[k] <- sum(diag(tablin))/nrow(test_data)
  }
  return (mean(succ))
}
```

### 
```{r}
# Symmetric shape variation
succ_S <- myFDA('Species_ID', 'PC1_symm_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Asymmetric shape variation
succ_A <- myFDA('Species_ID', 'PC1_asym_mean + PC2_asym_mean + PC3_asym_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Global shape variation
succ_G <- myFDA('Species_ID', 'PC1_glob_mean + PC2_glob_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Length + width
succ_LW <- myFDA('Species_ID', 'Length_mean + Width_mean', mydata = traits_merged, part = 0.7, rep = 1000)

#  Length to width ratio
succ_Q <- myFDA('Species_ID', 'Length_to_width_ratio_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Total variation as Q & size
succ_QLW <- myFDA('Species_ID', 'Length_to_width_ratio_mean + Length_mean + Width_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Total variation as global shape + size
succ_GLW <- myFDA('Species_ID', 'PC1_glob_mean + PC2_glob_mean + Length_mean + Width_mean', mydata = traits_merged, part = 0.7, rep = 1000)

# Total variation shape symmetric + asymmetric & size
succ_SALW <- myFDA('Species_ID', 'PC1_symm_mean + 
               PC1_asym_mean + PC2_asym_mean + PC3_asym_mean + 
               Length_mean + Width_mean', mydata = traits_merged, part = 0.7, rep = 1000)
```

All success rates in a single table
```{r}
succ_all <- t(data.frame(succ_S,
                         succ_A,
                         succ_G,
                         succ_LW,
                         succ_Q,
                         succ_QLW,
                         succ_GLW,
                         succ_SALW))
succ_all                          
```

Re-format and plot the identification success rates
```{r}
succ_all_df <- data.frame(succ_all)
# row.names(data.frame(succ_all)) # to retrieve the names of the predictors and adjust them
# succ_all_df$Predictors <- row.names(data.frame(succ_all))
succ_all_df$Predictors <- c('S', 'A', 'G', 'LW', 'Q', 'QLW',  'GLW', 'SALW')

names(succ_all_df)[1] <- 'Success' 
succ_all_df[1] <- round(succ_all_df[1]*100, 1) # switch to percents

# make the predicors factors, instead of characters. This will keep their original order while plotting. 
succ_all_df$Predictors <- factor(succ_all_df$Predictors, levels = succ_all_df$Predictors)
p <- ggplot(succ_all_df, aes(x=reorder(Predictors, Success), y=Success)) +
  geom_bar(stat="identity", fill="steelblue") +
  xlab('Predictors') +
  ylab('Identification success rate, %') + 
  coord_flip(ylim = c(45, 65)) + 
  geom_text(aes(label=Success), vjust=0.5, hjust = 1.4, size = 4, color="white")
  theme(axis.title = element_text(size = 16), axis.text = element_text(size = 12))
p
```
Save id success rates plot
```{r}
# tiff
tiff(file = here::here("3_results", "fig_success.tiff"), height= 9, width=12, units = 'cm', res = 600,
     compression = "lzw", family = "sans")
print(p)
dev.off()

# png(file = here::here("3_results", "bar_dis.png"), height= 9, width=12, units = 'cm', res = 300)
# print(p)
# dev.off()
```



## Phylogenetic tree that justifies the assignment of specimens to species  

### Load DNA sequences to R memory
```{r message = FALSE}
library(Biostrings)
conflicted::conflict_prefer("strsplit", "Biostrings")
seq <- readDNAStringSet(here::here("2_1_data_dna", "202103", "its_30seq.fasta"))
# seq@ranges@NAMES # seq names are here, work on names later if necessary
```

### Multiple sequence alignment (MSA)
```{r}
library(msa)
ali_XString <- msa::msa(seq, type="dna", method="Muscle")
#the run took 11.45 seconds for 48 ITS sequences on my Dell laptop in Aug 2020

library(ape)
# convert the alignment to DNAbin
ali_bin <- as.DNAbin(ali_XString)
```

### Plot MSA
#### Untrimmed MSA
```{r}
par(mar=c(3,7,3,3))
image(ali_bin, cex.lab = 0.8)
```

#### Trimmed MSA
Trimm the ends of aligment and plot again
```{r}
# package ips is required
# to make ips working properly, I had to install XML package from binary
# install.packages("XML", type = "binary")
library(ips)
ali_trimmed <- trimEnds(ali_bin, min.n.seq = 15)
par(mar=c(3,10,3,9))
image(ali_trimmed, cex.lab = 0.8)
```


### Maximum Likelihood phylogenetic analysis
```{r}
library(phangorn)
conflicted::conflict_prefer("rename", "S4Vectors")
mt <- modelTest(phyDat(ali_trimmed), model="all", control = pml.control(trace = 0))
# choose best model to your preferred information criteria
bestModel <- mt$Model[which.min(mt$AIC)]
# "some R magic" - citation from Klaus Schliep
env <- attr(mt, "env")
fitStart <- eval(get(bestModel, env), env=env)
# optimize model
fit.nni <- optim.pml(fitStart, rearrangement="NNI", control = pml.control(trace = 0))
# bootstrap analysis
bs <- bootstrap.pml(fit.nni, bs=1000, optNni=TRUE, control = pml.control(trace = 0))

# save the tree with bootstrap supports as node labels in phylo object
tree.bs <- plotBS(fit.nni$tree, bs, type="phylo")
```

What was the best substitution model?
```{r}
bestModel
```
Save the tree to file
```{r}
ape::write.tree(tree.bs, file = here::here("3_results", "tree_1000bs.newick"))
```


### Custom plotting of the tree
```{r}

# reroot the tree
tree.bs <- root(tree.bs, c("KHL_10272", "KHL_10780", "KHL_10813"), resolve.root = T)

library(ggtree)
library(ggplot2)

# add species names if not already done in the morphometric part of the script
sp_names <- read.csv(here::here("3_results", "species_names.csv"),  sep=",", stringsAsFactors=FALSE)
# now a complex operator will add the species names to the object
# it aligns the species names to sequence labels correctly - I've checked this manually
# there will be an error message that the number of replaced elements does not equal the
# total number of elements in the labels, but it is OK because we only assign the species names to the 
# terminal node labels = tip labels, and not to internal node labels (which are bootstrap supports here)
p0 <- ggtree(tree.bs) %<+% sp_names
```

Now setting all aestetics 
```{r}
p1 <- p0 + 
  geom_tree(size=0.1) +
  geom_tiplab(aes(color = Species_ID), key_glyph = draw_key_point, size=2, align=F, hjust=-0.01) + 
  geom_text2(aes(subset = !isTip, label=label), size = 2, vjust = -0.7, hjust = 1.2) + 
  geom_treescale(linesize = 0.5, fontsize = 2, x = 0.85, y = 16.5) + 
  geom_text(label="substitutions per site", x=1, y=16.0, 
            size = 6 / .pt, fontface = 'plain', family = 'sans', stat = "unique") + 
  # this 'stat = 'unique'' makes the text font the same as inner ggploting
  xlim(-0.04, 1.2) + 
  theme(legend.position=c(0.8, 0.81),
        legend.background = element_rect(), 
        legend.key = element_blank(), # removes the border
        legend.key.size = unit(0.4, 'cm'),# sets overall area/size of the legend 
        legend.text = element_text(size = 6), # text size 
        title = element_text(size = 7)) + 
  theme(plot.margin = unit(c(0.1, 0, 0.1, 0.2), "cm")) 
  # +labs(col="Subulicystidium \n species") # would change legend title
```


Print the tree to a file(s)
```{r}
# tiff via tiff()
tiff(filename = here::here("3_results", "fig_tree.tiff"), height= 12, width=9, units = 'cm', res = 600, 
     compression = "lzw", family = "sans")
print(p1)
dev.off()

# tiff via ggsave
# ggsave(filename = here::here("3_results", "fig_tree_20BS.tiff"), plot = p1, height= 12, width=9, units = 'cm', dpi = 400)

# # pdf
# pdf(file = here::here("3_results", "fig_tree.pdf"), height=5.0, width=3.5)
# print(p1)
# dev.off()
# 
# # png
# png(file = here::here("3_results", "fig_tree.png"), height= 12, width=9, units = 'cm', res = 500)
# print(p1)
# dev.off()
```

End of the script.
